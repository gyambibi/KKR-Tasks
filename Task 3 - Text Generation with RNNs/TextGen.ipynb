{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('shakespeare.txt', 'rb').read().decode(encoding='utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = sorted(set(text))\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the text (Mapping characters to numbers)\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(unique)}\n",
    "idx2char = np.array(unique)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '$' :   3,\n",
      "  '&' :   4,\n",
      "  \"'\" :   5,\n",
      "  ',' :   6,\n",
      "  '-' :   7,\n",
      "  '.' :   8,\n",
      "  '3' :   9,\n",
      "  ':' :  10,\n",
      "  ';' :  11,\n",
      "  '?' :  12,\n",
      "  'A' :  13,\n",
      "  'B' :  14,\n",
      "  'C' :  15,\n",
      "  'D' :  16,\n",
      "  'E' :  17,\n",
      "  'F' :  18,\n",
      "  'G' :  19,\n",
      "  'H' :  20,\n",
      "  'I' :  21,\n",
      "  'J' :  22,\n",
      "  'K' :  23,\n",
      "  'L' :  24,\n",
      "  'M' :  25,\n",
      "  'N' :  26,\n",
      "  'O' :  27,\n",
      "  'P' :  28,\n",
      "  'Q' :  29,\n",
      "  'R' :  30,\n",
      "  'S' :  31,\n",
      "  'T' :  32,\n",
      "  'U' :  33,\n",
      "  'V' :  34,\n",
      "  'W' :  35,\n",
      "  'X' :  36,\n",
      "  'Y' :  37,\n",
      "  'Z' :  38,\n",
      "  'a' :  39,\n",
      "  'b' :  40,\n",
      "  'c' :  41,\n",
      "  'd' :  42,\n",
      "  'e' :  43,\n",
      "  'f' :  44,\n",
      "  'g' :  45,\n",
      "  'h' :  46,\n",
      "  'i' :  47,\n",
      "  'j' :  48,\n",
      "  'k' :  49,\n",
      "  'l' :  50,\n",
      "  'm' :  51,\n",
      "  'n' :  52,\n",
      "  'o' :  53,\n",
      "  'p' :  54,\n",
      "  'q' :  55,\n",
      "  'r' :  56,\n",
      "  's' :  57,\n",
      "  't' :  58,\n",
      "  'u' :  59,\n",
      "  'v' :  60,\n",
      "  'w' :  61,\n",
      "  'x' :  62,\n",
      "  'y' :  63,\n",
      "  'z' :  64,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(65)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "#  creating training examples and targets\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "' are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n",
      "\" know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us\"\n",
      "\" kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it \"\n",
      "'be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 99), dtype=tf.int64, name=None), TensorSpec(shape=(64, 99), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making batches\n",
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(unique)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, output_dim=256, input_length=None),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size = len(unique),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 99) (64, 99)\n"
     ]
    }
   ],
   "source": [
    "# Trying\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(input_example_batch.shape, target_example_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m1024\u001b[0m)         │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m65\u001b[0m)           │        \u001b[38;5;34m66,625\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sample_indices = tf.squeeze(sample_indices,axis= -1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 30,  0, 52, 10, 12, 12, 44,  4, 51, 46, 27, 50, 17, 45, 37, 44,\n",
       "       54, 45, 20, 26, 54, 34, 14, 61, 55, 44,  1, 56, 54, 57, 29, 52, 21,\n",
       "       54,  6, 17,  0,  0, 57, 27, 17, 37, 42, 42, 22, 53, 62, 47, 11, 33,\n",
       "        6, 39, 21, 51, 24, 56, 52, 61, 54, 33, 38, 16,  2, 53, 26, 12, 20,\n",
       "       16, 15, 33, 35, 43, 51, 42, 63, 60, 31, 29, 33, 16,  0, 55, 26, 42,\n",
       "       13, 12, 22, 45, 53,  2,  3,  8,  0, 24, 45, 24, 33, 41])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'the point of death\\nHave they been merry! which their keepers call\\nA lightning before death: O, how '\n",
      "\n",
      "Next character prediction:  'yR\\nn:??f&mhOlEgYfpgHNpVBwqf rpsQnIp,E\\n\\nsOEYddJoxi;U,aImLrnwpUZD!oN?HDCUWemdyvSQUD\\nqNdA?Jgo!$.\\nLgLUc'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next character prediction: \", repr(\"\".join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 99, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.173333\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 583ms/step - loss: 2.8796\n",
      "Epoch 2/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 582ms/step - loss: 1.8654\n",
      "Epoch 3/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 599ms/step - loss: 1.6119\n",
      "Epoch 4/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 603ms/step - loss: 1.4896\n",
      "Epoch 5/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 608ms/step - loss: 1.4110\n",
      "Epoch 6/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 608ms/step - loss: 1.3571\n",
      "Epoch 7/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 2s/step - loss: 1.3171\n",
      "Epoch 8/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 587ms/step - loss: 1.2804\n",
      "Epoch 9/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 594ms/step - loss: 1.2439\n",
      "Epoch 10/10\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 602ms/step - loss: 1.2145\n"
     ]
    }
   ],
   "source": [
    "HISTORY = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available checkpoints: ['ckpt_7.weights.h5', 'ckpt_2.weights.h5', 'ckpt_8.weights.h5', 'ckpt_5.weights.h5', 'ckpt_3.weights.h5', 'ckpt_6.weights.h5', 'ckpt_1.weights.h5', 'ckpt_10.weights.h5', 'ckpt_9.weights.h5', 'ckpt_4.weights.h5']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available checkpoints:\", os.listdir(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint: ./training_checkpoints/ckpt_9.weights.h5\n"
     ]
    }
   ],
   "source": [
    "# Finding the latest checkpoint\n",
    "checkpoint_files = sorted(os.listdir(checkpoint_dir))\n",
    "latest_checkpoint = os.path.join(checkpoint_dir, checkpoint_files[-1])  # Picking the latest one\n",
    "\n",
    "# Building and loading model\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.load_weights(latest_checkpoint)  # Load weights\n",
    "\n",
    "print(\"Loaded checkpoint:\", latest_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate=1000):\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        predictions = model(input_eval)  \n",
    "\n",
    "        predicted_id = tf.random.categorical(predictions[:, -1, :], num_samples=1).numpy()[0, 0]\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: Aft, princely Counteduse;\n",
      "The churchy may be a fellow-roood; am\n",
      "taken my will.\n",
      "\n",
      "First Soloved'd,\n",
      "Hath shator for your hands. Good Hants,\n",
      "Nor cannot need make me? there be in\n",
      "commond, either than things eye\n",
      "That manhules are fourteen; what fair daughter?\n",
      "Thus, call the other.\n",
      "\n",
      "CURTIS:\n",
      "And silent no lands she's set more prosper maning bold?\n",
      "We seel our son'stain'd flose thing or now,\n",
      "For he thought in seeming bolds,\n",
      "Which thou spoke point to all the bonds and feel pause?\n",
      "\n",
      "TRANIO:\n",
      "'Tis a true and not hard malls amongst I die.\n",
      "Why dost thou art a sister, a movinio should rail issue, who crots\n",
      "but in my imagine cannot stur and wed; not of Salisbury, who, trunks it strength,\n",
      "Tybalt spoils, I here,\n",
      "And will me resolve as death:\n",
      "Having thee ne'er then changed up, here brings,\n",
      "And let us see no to his hands.\n",
      "\n",
      "EIRIA:\n",
      "True Hermione, in York, that man stand, boy\n",
      "Are old mady crowns, bleasted down'd have each ter-in-plant;\n",
      "The kingly day shalt look up\n",
      "In banished all poor wars in degree,\n",
      "That it ha\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
